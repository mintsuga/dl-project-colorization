{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import skimage\n",
    "from skimage.color import rgb2gray\n",
    "import keras\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CifarGenerator(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    a generator of Cifar dataset\n",
    "    use 'for' iteration to generate image in batch-manner\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir, batch_size, is_training=True, shuffle=True):\n",
    "        self.img_dir = img_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self._is_training = is_training\n",
    "\n",
    "        self._img_names = []\n",
    "\n",
    "        self.indexes = np.arange(len(self.img_names))\n",
    "\n",
    "        self.w = 32\n",
    "        self.h = 32\n",
    "\n",
    "    def __len__(self):\n",
    "        # how many batches \n",
    "        return int(np.ceil(len(self.indexes) / float(self.batch_size)))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.is_training and self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        upper_bound = min(self.size, (index + 1) * self.batch_size)\n",
    "        indexes = self.indexes[index * self.batch_size:upper_bound]\n",
    "\n",
    "        images_A = []\n",
    "        images_B = []\n",
    "        \n",
    "        for index in indexes:\n",
    "            f_name = self._img_names[index]\n",
    "            image_A = scipy.misc.imread(f_name, mode='RGB').astype(np.float)\n",
    "            image_B = rgb2gray(image_A)\n",
    "        \n",
    "            image_A = scipy.misc.imresize(image_A, (self.h, self.w))\n",
    "            image_B = scipy.misc.imresize(image_B, (self.h, self.w))\n",
    "            \n",
    "            # convert gray-scale image to a 3-channel image to fit input shape\n",
    "            image_B = np.stack((image_B,)*3, axis=-1)\n",
    "                \n",
    "            images_A.append(image_A)\n",
    "            images_B.append(image_B)\n",
    "        \n",
    "        # normalization is to bring the values in range [-1.0,1.0]\n",
    "        images_A = np.array(images_A)/127.5 - 1.\n",
    "        images_B = np.array(images_B)/127.5 - 1.\n",
    "        \n",
    "        return images_A, images_B\n",
    "        \n",
    "    def _load(self):\n",
    "        for f_name in tqdm(os.listdir(self.img_dir)):\n",
    "            if os.path.splitext(f_name)[-1] == '.png':\n",
    "                self._img_names.append(os.path.join(self.img_dir, f_name))\n",
    "\n",
    "    @property\n",
    "    def img_names(self):\n",
    "        if len(self._img_names) == 0:\n",
    "            self._load()\n",
    "        return self._img_names\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self._img_names)\n",
    "\n",
    "    @property\n",
    "    def is_training(self):\n",
    "        return self._is_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/data_service/source_datasets/cifar_images/images_train'\n",
    "TEST_DIR = '/data_service/source_datasets/cifar_images/images_test'\n",
    "\n",
    "# simple test\n",
    "# for x, y in generator:\n",
    "#     print(x.shape, y.shape)  # (16, 32, 32, 3) (16, 32, 32, 3)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pix2pixColorizer():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.h = 32\n",
    "        self.w = 32\n",
    "        self.num_channel = 3\n",
    "        self.image_shape = (self.h, self.w, self.num_channel)\n",
    "        \n",
    "        self.image_A = Input(shape=self.image_shape)\n",
    "        self.image_B = Input(shape=self.image_shape)\n",
    "        \n",
    "        self.build_gan()\n",
    "    \n",
    "    def load_generator(self, g_model):\n",
    "        self.generator.load_weights(g_model)\n",
    "    \n",
    "    def build_gan(self):\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='mse', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        self.fake_A = self.generator(self.image_B)\n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        self.valid = self.discriminator([self.fake_A, self.image_B])\n",
    "        self.combined = Model(inputs=[self.image_A, self.image_B], outputs=[self.valid, self.fake_A])\n",
    "        self.combined.compile(loss=['mse', 'mae'], loss_weights=[1, 100], optimizer=Adam(0.0002, 0.5))\n",
    "        \n",
    "        self.disc_patch = (int(self.h/2**4), int(self.w/2**4), 1)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        image_A = Input(shape=self.image_shape)\n",
    "        image_B = Input(shape=self.image_shape)\n",
    "        \n",
    "        # concat axis=channel axis\n",
    "        combined_images = Concatenate(axis=-1)([image_A, image_B])\n",
    "        \n",
    "        # layer 1\n",
    "        d1 = Conv2D(filters=64, kernel_size=4, strides=2, padding='same')(combined_images)\n",
    "        d1 = LeakyReLU(alpha=0.2)(d1)\n",
    "        \n",
    "        # layer 2\n",
    "        d2 = Conv2D(filters=128, kernel_size=4, strides=2, padding='same')(d1)\n",
    "        d2 = LeakyReLU(alpha=0.2)(d2)\n",
    "        d2 = BatchNormalization(momentum=0.8)(d2)\n",
    "        \n",
    "        # layer 3\n",
    "        d3 = Conv2D(filters=128, kernel_size=4, strides=2, padding='same')(d2)\n",
    "        d3 = LeakyReLU(alpha=0.2)(d3)\n",
    "        d3 = BatchNormalization(momentum=0.8)(d3)\n",
    "        \n",
    "        # layer 4\n",
    "        d4 = Conv2D(filters=128, kernel_size=4, strides=2, padding='same')(d3)\n",
    "        d4 = LeakyReLU(alpha=0.2)(d4)\n",
    "        d4 = BatchNormalization(momentum=0.8)(d4)\n",
    "        \n",
    "        # 1-dim output\n",
    "        validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n",
    "        \n",
    "        return Model([image_A, image_B], validity)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        \n",
    "        d0 = Input(shape=self.image_shape)\n",
    "        \n",
    "        # layer 1\n",
    "        d1 = Conv2D(filters=64, kernel_size=4, strides=2, padding='same')(d0)\n",
    "        d1 = LeakyReLU(alpha=0.2)(d1)\n",
    "        \n",
    "        # layer 2\n",
    "        d2 = Conv2D(filters=128, kernel_size=4, strides=2, padding='same')(d1)\n",
    "        d2 = LeakyReLU(alpha=0.2)(d2)\n",
    "        d2 = BatchNormalization(momentum=0.8)(d2)\n",
    "        \n",
    "        # layer 3\n",
    "        d3 = Conv2D(filters=256, kernel_size=4, strides=2, padding='same')(d2)\n",
    "        d3 = LeakyReLU(alpha=0.2)(d3)\n",
    "        d3 = BatchNormalization(momentum=0.8)(d3)\n",
    "        \n",
    "        # layer 4\n",
    "        d4 = Conv2D(filters=512, kernel_size=4, strides=2, padding='same')(d3)\n",
    "        d4 = LeakyReLU(alpha=0.2)(d4)\n",
    "        d4 = BatchNormalization(momentum=0.8)(d4)\n",
    "        \n",
    "        # layer 5\n",
    "        d5 = Conv2D(filters=512, kernel_size=4, strides=2, padding='same')(d4)\n",
    "        d5 = LeakyReLU(alpha=0.2)(d5)\n",
    "        d5 = BatchNormalization(momentum=0.8)(d5)\n",
    "        \n",
    "        # layer 4\n",
    "        u4 = UpSampling2D(size=2)(d5)\n",
    "        u4 = Conv2D(filters=512, kernel_size=4, strides=1, padding='same', activation='relu')(u4)\n",
    "        u4 = BatchNormalization(momentum=0.8)(u4)\n",
    "        u4 = Concatenate()([u4, d4])\n",
    "        \n",
    "        # layer 3\n",
    "        u3 = UpSampling2D(size=2)(u4)\n",
    "        u3 = Conv2D(filters=256, kernel_size=4, strides=1, padding='same', activation='relu')(u3)\n",
    "        u3 = BatchNormalization(momentum=0.8)(u3)\n",
    "        u3 = Concatenate()([u3, d3])\n",
    "        \n",
    "        # layer 2\n",
    "        u2 = UpSampling2D(size=2)(u3)\n",
    "        u2 = Conv2D(filters=128, kernel_size=4, strides=1, padding='same', activation='relu')(u2)\n",
    "        u2 = BatchNormalization(momentum=0.8)(u2)\n",
    "        u2 = Concatenate()([u2, d2])\n",
    "        \n",
    "        # layer 1\n",
    "        u1 = UpSampling2D(size=2)(u2)\n",
    "        u1 = Conv2D(filters=64, kernel_size=4, strides=1, padding='same', activation='relu')(u1)\n",
    "        u1 = BatchNormalization(momentum=0.8)(u1)\n",
    "        u1 = Concatenate()([u1, d1])\n",
    "        \n",
    "        # layer 0\n",
    "        u0 = UpSampling2D(size=2)(u1)\n",
    "        \n",
    "        # 3-dim output\n",
    "        u0 = Conv2D(self.num_channel, kernel_size=4, strides=1, padding='same', activation='tanh')(u0)\n",
    "        \n",
    "        return Model(d0, u0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorizer = pix2pixColorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "SAVED_DIR = './samples'\n",
    "\n",
    "def save_intermediate_images(save_dir, batch_i, images_A, images_B, fake_images_A):\n",
    "    assert images_A.shape[0] == images_B.shape[0] == fake_images_A.shape[0]\n",
    "    \n",
    "    batch_size = images_A.shape[0]\n",
    "    generated_image = Image.new('RGB', (32*3, 32*batch_size))\n",
    "    for batch_cnt in range(batch_size):\n",
    "        image_A = np.uint8((np.array(images_A[batch_cnt]) * 0.5 + 0.5) * 255)\n",
    "        image_B = np.uint8((np.array(images_B[batch_cnt]) * 0.5 + 0.5) * 255)\n",
    "        image_fake_A = np.uint8((np.array(fake_A[batch_cnt]) * 0.5 + 0.5) * 255)\n",
    "        \n",
    "        image_A = Image.fromarray(image_A)\n",
    "        image_B = Image.fromarray(image_B)\n",
    "        image_fake_A = Image.fromarray(image_fake_A)\n",
    "        \n",
    "        generated_image.paste(image_B,      (0, batch_cnt*32, 32, (batch_cnt+1)*32))\n",
    "        generated_image.paste(image_fake_A, (32, batch_cnt*32, 32*2, (batch_cnt+1)*32))\n",
    "        generated_image.paste(image_A,      (32*2, batch_cnt*32, 32*3, (batch_cnt+1)*32))\n",
    "    \n",
    "    generated_image.save(save_dir + \"/G_%d.jpg\" % batch_i, quality=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    batch_size = 64\n",
    "    data_generator = CifarGenerator(img_dir=TRAIN_DIR, batch_size=batch_size, is_training=True)\n",
    "\n",
    "    valid = np.ones((batch_size,) + colorizer.disc_patch)\n",
    "    fake = np.zeros((batch_size,) + colorizer.disc_patch)\n",
    "\n",
    "    for batch_cnt, (images_A, images_B) in enumerate(tqdm(data_generator)):\n",
    "    #     print(images_A.shape)  # (batch_size, 32, 32, 3)\n",
    "    #     print(images_B.shape)  # (batch_size, 32, 32, 3)\n",
    "\n",
    "        # last batch, less samples\n",
    "        if images_A.shape[0] != batch_size:\n",
    "            valid = np.ones((images_A.shape[0],) + colorizer.disc_patch)\n",
    "            fake = np.zeros((images_A.shape[0],) + colorizer.disc_patch)\n",
    "\n",
    "        fake_A = colorizer.generator.predict(images_B)\n",
    "\n",
    "        d_loss_real = colorizer.discriminator.train_on_batch([images_A, images_B], valid)\n",
    "        d_loss_fake = colorizer.discriminator.train_on_batch([fake_A, images_B], fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        g_loss = colorizer.combined.train_on_batch([images_A, images_B], [valid, images_A])\n",
    "\n",
    "        if batch_cnt and not batch_cnt % 200:\n",
    "            print (\"[Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %f]\" % \n",
    "                           (batch_cnt+1, len(generator), \n",
    "                            d_loss[0], 100*d_loss[1], g_loss[0]))\n",
    "            save_intermediate_images(SAVED_DIR, batch_cnt, images_A, images_B, fake_A)\n",
    "\n",
    "    colorizer.generator.save_weights('g_weights.h5')\n",
    "    colorizer.discriminator.save_weights('d_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 164313.04it/s]\n",
      "  0%|          | 0/625 [00:00<?, ?it/s]/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:39: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "100%|██████████| 625/625 [00:52<00:00, 11.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# test process\n",
    "batch_size = 16\n",
    "colorizer.load_generator('g_weights_20.h5')  # generator params with 20-epoch training\n",
    "data_generator = CifarGenerator(img_dir=TEST_DIR, batch_size=batch_size)\n",
    "\n",
    "SAVED_DIR = './Res'\n",
    "for batch_cnt, (images_A, images_B) in enumerate(tqdm(data_generator)):\n",
    "    fake_A = colorizer.generator.predict(images_B)\n",
    "    save_intermediate_images(SAVED_DIR, batch_cnt, images_A, images_B, fake_A)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
